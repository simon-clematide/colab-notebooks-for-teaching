{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZtyoOEFxJ1gN"
      ],
      "authorship_tag": "ABX9TyP80rY5xkF0Ko5fLhitMZoh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simon-clematide/colab-notebooks-for-teaching/blob/main/sentiment-analysis-overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we run on cpu only, it can be  faster to use the following pip install\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "# Otherwise use the following line\n",
        "%pip install flair # lets do this first to prevent restarting the runtime"
      ],
      "metadata": {
        "id": "wmNyzsn1PIOk",
        "outputId": "d25cae1d-0c85-4b04-e22b-9dd9a3bcd2c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.11/dist-packages (0.15.1)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.11/dist-packages (from flair) (1.37.7)\n",
            "Requirement already satisfied: conllu<5.0.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair) (1.2.18)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.11/dist-packages (from flair) (6.3.1)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.28.1)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.11/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair) (5.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (3.10.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.11/dist-packages (from flair) (10.6.0)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.11/dist-packages (from flair) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.11/dist-packages (from flair) (3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from flair) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair) (1.6.1)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.11/dist-packages (from flair) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from flair) (2.5.1+cpu)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from flair) (4.67.1)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from flair) (0.4.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.48.3)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from flair) (0.8.1)\n",
            "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from flair) (2.1)\n",
            "Requirement already satisfied: jsonlines>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (4.0.0)\n",
            "Requirement already satisfied: intervaltree in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from bioc<3.0.0,>=2.0.0->flair) (0.6.2)\n",
            "Requirement already satisfied: botocore<1.38.0,>=1.37.7 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (1.37.7)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3>=1.20.27->flair) (0.11.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect>=1.0.9->flair) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mpld3>=0.3->flair) (3.1.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->flair) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (4.25.6)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.7->boto3>=1.20.27->flair) (2.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (25.1.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.6)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment and Emotion Analysis\n",
        "\n",
        "1. **Definition**: Sentiment analysis is a computational technique in natural language processing (NLP) that identifies and categorizes opinions or emotions within text data to determine the writer's attitude towards a particular topic, product, or service.\n",
        "\n",
        "2. **Applications**: It's widely used in business and marketing for brand monitoring, product reviews analysis, customer feedback, and social media monitoring, helping organizations understand consumer sentiments and preferences.\n",
        "\n",
        "3. **Techniques and Challenges**: Sentiment analysis often employs machine learning, lexical methods, or a combination of both. It faces challenges like detecting sarcasm, context, cultural variations, and nuanced expressions of emotions."
      ],
      "metadata": {
        "id": "kP1-D911zEBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our running examples from \"[Pride and Prejudice](https://www.gutenberg.org/ebooks/42671)\" will be:\n",
        "- a prototypical positive sentence `sent`: \"Mr Davis is a handsome man.\"\n",
        "- a phrase with a negation `neg`: \"Elizabeth did't feel happy.\"\n",
        "- a long literary sentence with nuanced expression `para` : \"Which do you mean?\" and turning round, he looked for a moment at Elizabeth, till catching her eye, he withdrew his own and coldly said, \"She is tolerable; but not handsome enough to tempt me; and I am in no humour at present to give consequence to young ladies who are slighted by other men. \""
      ],
      "metadata": {
        "id": "JGLzM6Dq2VlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"Mr Davis is a handsome man.\"\n",
        "neg =  \"Elizabeth didn't feel happy.\"\n",
        "para = '''\"Which do you mean?\" and turning round, he looked for a moment at Elizabeth, till catching her eye, he withdrew his own and coldly said,\n",
        "\"She is tolerable; but not handsome enough to tempt me; and I am in no humour at present to give consequence to young ladies who are slighted by other men.\"'''"
      ],
      "metadata": {
        "id": "8-uHhzR_CY77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lexical Approaches\n",
        "They rely on word/lemma lists that have been categorized into sentiment classes."
      ],
      "metadata": {
        "id": "wHPMaKBR0idL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VaderSentiment\n",
        "Gives an overall assessment of a text. What is negative, neutral, positive in terms of [words](https://github.com/cjhutto/vaderSentiment/blob/master/vaderSentiment/vader_lexicon.txt) and phrases. Aggregated in a compound value that gives an [overall score](https://github.com/cjhutto/vaderSentiment?tab=readme-ov-file#about-the-scoring) between -1 and 1. More on https://github.com/cjhutto/vaderSentiment"
      ],
      "metadata": {
        "id": "RM_WpyzRDM9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install vaderSentiment"
      ],
      "metadata": {
        "id": "TYCqSLZbngnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "Ve3zet-zpCgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vs = analyzer.polarity_scores(sent)\n",
        "print(sent, vs, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "ch9NuBiwpKNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vs = analyzer.polarity_scores(neg)\n",
        "print(neg, vs, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "zvNYuOs7D6O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vs = analyzer.polarity_scores(para)\n",
        "print(para, vs, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "led8dpiSE1vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# intensifiers are respected\n",
        "vs = analyzer.polarity_scores(\"Mr Davis is an extremely handsome man.\")\n",
        "print(vs)"
      ],
      "metadata": {
        "id": "IFPbPJqEFuW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neutral words matter\n",
        "# intensifiers are respected\n",
        "vs = analyzer.polarity_scores(\"extremely handsome\")\n",
        "print(vs)"
      ],
      "metadata": {
        "id": "_7HFTlPuGB2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(SentimentIntensityAnalyzer)"
      ],
      "metadata": {
        "id": "z_NhPQ4-pMqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texblob\n",
        "Yet another NLP pipeline with [lexicon-based sentiment and polarity analysis](https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis)"
      ],
      "metadata": {
        "id": "gmFit1xnIJys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install textblob\n"
      ],
      "metadata": {
        "id": "C1s07gSOj2rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "iz4VtkTQnTPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_result = TextBlob(sent)\n",
        "print(sent, sent_result.sentiment,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "jQIU2Hupnc8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_result = TextBlob(neg)\n",
        "print(neg, neg_result.sentiment,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "wIShxOvxI6-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para_result = TextBlob(para)\n",
        "print(para, para_result.sentiment,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "RM-OWo0UJS7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = TextBlob(\"handsome\")\n",
        "print(result.sentiment,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "Q_f2yNRHJkCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NRCLex\n",
        "An analyser for [sentiment (positive/negative) and basic emotions](https://github.com/metalcorebear/NRCLex). Simple lexical lookup."
      ],
      "metadata": {
        "id": "Z8nSWMbpP7vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install NRCLex"
      ],
      "metadata": {
        "id": "pVJVK6lyuhC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nrclex import NRCLex"
      ],
      "metadata": {
        "id": "hOL_BjLBwUUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = NRCLex(sent)\n",
        "print(sent, analysis.raw_emotion_scores, analysis.affect_dict, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "su3eRm_-wQM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = NRCLex(neg)\n",
        "print(neg, analysis.raw_emotion_scores, analysis.affect_dict, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "TdJnFxfAwcIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis = NRCLex(para)\n",
        "print(para, analysis.raw_emotion_scores, analysis.affect_dict, sep=\"\\n\")"
      ],
      "metadata": {
        "id": "gcV8-4lOwkxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Approaches\n",
        "Typically trained on a variety of training sets: IMDB (Movie reviews), Tweets, etc."
      ],
      "metadata": {
        "id": "mLyR6Nwz1JU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spaCy\n",
        "A [spaCy-based textcategorization](https://github.com/Vishnunkumar/eng_spacysentiment) (textcat) NLP pipeline (tokensization and text classification). Trained on IMDB movie review dataset."
      ],
      "metadata": {
        "id": "ZtyoOEFxJ1gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install eng-spacysentiment"
      ],
      "metadata": {
        "id": "w-lUc-cOp5rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import eng_spacysentiment\n",
        "nlp = eng_spacysentiment.load()"
      ],
      "metadata": {
        "id": "wjw09Z1puCSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_doc = nlp(sent)\n",
        "print(sent,sent_doc.cats,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "S642f_1zuLfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neg_doc = nlp(neg)\n",
        "print(neg,neg_doc.cats,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "0pGKyEEAuNHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para_doc = nlp(para)\n",
        "print(para,para_doc.cats,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "zRx_jNzCuN76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"handsome\")\n",
        "print(doc.cats,sep=\"\\n\")"
      ],
      "metadata": {
        "id": "FYAhki5HLqop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# some information on the pipeline\n",
        "nlp.meta"
      ],
      "metadata": {
        "id": "7bPFQsj6uaUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## flair Sentiment\n",
        "Another neural model with [different models for sentiment analysis](https://flairnlp.github.io/docs/tutorial-basics/tagging-sentiment)."
      ],
      "metadata": {
        "id": "UxTdgDfsKBFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install gensim"
      ],
      "metadata": {
        "id": "fisA9DHsgOQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "\n",
        "classifier = TextClassifier.load('sentiment-fast')"
      ],
      "metadata": {
        "id": "jVM1CdsHeQig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=Sentence(sent)\n",
        "classifier.predict(sentence)\n",
        "print(sent, sentence.to_dict()[\"labels\"], sep=\"\\n\")"
      ],
      "metadata": {
        "id": "hcJwfy_febdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=Sentence(neg)\n",
        "classifier.predict(sentence)\n",
        "print(neg, sentence.to_dict()[\"labels\"], sep=\"\\n\")"
      ],
      "metadata": {
        "id": "zU3KhjhCe6p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=Sentence(para)\n",
        "classifier.predict(sentence)\n",
        "print(para, sentence.to_dict()[\"labels\"], sep=\"\\n\")"
      ],
      "metadata": {
        "id": "lL2nwIHFe8rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can run words and phrases through flair\n",
        "text = \"not handsome enough\"\n",
        "sentence=Sentence(text)\n",
        "classifier.predict(sentence)\n",
        "print(text, sentence.to_dict()[\"labels\"], sep=\"\\n\")"
      ],
      "metadata": {
        "id": "vObi3C6te_J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer-based Model on Huggingface\n",
        "A fine-tuned robert model. Try it on huggingface: https://huggingface.co/siebert/sentiment-roberta-large-english"
      ],
      "metadata": {
        "id": "gaip_yoLOWkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")\n",
        "\n"
      ],
      "metadata": {
        "id": "t2YslyOySuFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent, sentiment_analysis(sent),sep=\"\\n\")"
      ],
      "metadata": {
        "id": "StFkf2BHTF1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(neg, sentiment_analysis(neg),sep=\"\\n\")"
      ],
      "metadata": {
        "id": "ivofx7baSu69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(para, sentiment_analysis(para),sep=\"\\n\")"
      ],
      "metadata": {
        "id": "SB8CIW6sS5w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "Lexial approaches have problems with nuanced sentiments or negation. Trained models have typically rather extreme values and might be biased towards the training data (tweets, reviews)."
      ],
      "metadata": {
        "id": "5rW5HKn4TU9O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zk_CMyDVTnDa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}