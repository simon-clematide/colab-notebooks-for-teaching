{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sklearn.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simon-clematide/colab-notebooks-for-teaching/blob/main/notebooks/topic_modeling_sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2Gbuq1DsIzC"
      },
      "source": [
        "# Setup\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft-MR3lqsWCk"
      },
      "source": [
        "%pip install gensim==4.3.3 numpy==1.26.4 pyldavis\n",
        "\n",
        "# colab has newer versions installed, we need to restart the runtime\n",
        "from IPython.display import HTML, display\n",
        "display(HTML(\"\"\"Please restart the runtime from the Menu Runtime if new packages were installed.<br><br>\n",
        "         <code>Runtime â†’ Restart runtime</code><br><br>\n",
        "    This is necessary to apply the newly installed packages.\n",
        "    \"\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try to avoid warnings but not really working for now\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"ipykernel.ipkernel\")\n"
      ],
      "metadata": {
        "id": "Ydh_3NUfucMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1s9S9LEsIzG"
      },
      "source": [
        "# `pyLDAvis`\n",
        "\n",
        "pyLDAvis now also supports LDA application from scikit-learn. Let's take a look into this in more detail. We will be using the 20 newsgroups dataset as provided by scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-QCt0lSQsIzG"
      },
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.lda_model\n",
        "pyLDAvis.enable_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjcrWF1VsIzI"
      },
      "source": [
        "## Load 20 newsgroups dataset\n",
        "\n",
        "First, the 20 newsgroups dataset available in sklearn is loaded. As always, the headers, footers and quotes are removed.\n",
        "\n",
        "Newsgroup categories:\n",
        "`['alt.atheism',\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'comp.sys.ibm.pc.hardware',\n",
        " 'comp.sys.mac.hardware',\n",
        " 'comp.windows.x',\n",
        " 'misc.forsale',\n",
        " 'rec.autos',\n",
        " 'rec.motorcycles',\n",
        " 'rec.sport.baseball',\n",
        " 'rec.sport.hockey',\n",
        " 'sci.crypt',\n",
        " 'sci.electronics',\n",
        " 'sci.med',\n",
        " 'sci.space',\n",
        " 'soc.religion.christian',\n",
        " 'talk.politics.guns',\n",
        " 'talk.politics.mideast',\n",
        " 'talk.politics.misc',\n",
        " 'talk.religion.misc']`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzlyi0f_sIzI"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHitBJqrsIzJ"
      },
      "source": [
        "cats = ['sci.med', 'alt.atheism', 'rec.autos', 'sci.space','rec.sport.baseball']\n",
        "newsgroups = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'),categories=cats)\n",
        "docs_raw = newsgroups.data\n",
        "print(len(docs_raw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQHMVL4asIzK"
      },
      "source": [
        "print(docs_raw[72])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxtpHRQssIzL"
      },
      "source": [
        "## Convert to document-term matrix\n",
        "\n",
        "Next, the raw documents are converted into document-term matrix, possibly as raw counts or in TF-IDF form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC3UB1yKsIzL"
      },
      "source": [
        "tf_vectorizer = CountVectorizer(strip_accents = 'unicode',\n",
        "                                stop_words = 'english',\n",
        "                                lowercase = True,\n",
        "                                token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
        "                                max_df = 0.5,  # exclude words with a relative document frequency greater than 50%\n",
        "                                min_df = 10    # exclude tokens that occur less than 10 times\n",
        "                                )\n",
        "dtm_tf = tf_vectorizer.fit_transform(docs_raw)\n",
        "print(dtm_tf.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does a certain document look like in this representation?\n",
        "# Get the mapping of column indices to vocabulary items\n",
        "index2vocabulary_item = tf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Get the dense matrix representation of the document-term matrix\n",
        "doc_index = 72  # Index of the document to show\n",
        "doc_matrix = dtm_tf.getrow(doc_index).toarray()\n",
        "\n",
        "# Print the words and their counts in the document\n",
        "for i, count in enumerate(doc_matrix[0]):\n",
        "    if count > 0:\n",
        "        word = index2vocabulary_item[i]\n",
        "        print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "id": "jM8VvNjPvPpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative, we can build a tf-idf document-term matrix"
      ],
      "metadata": {
        "id": "8fFYC8CaFE6d"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NikLmiOosIzM"
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(**tf_vectorizer.get_params())\n",
        "dtm_tfidf = tfidf_vectorizer.fit_transform(docs_raw)\n",
        "print(dtm_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How does a certain document look like in this representation?\n",
        "# Get the mapping of column indices to vocabulary items\n",
        "index2vocabulary_item = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Get the dense matrix representation of the document-term matrix\n",
        "doc_index = 72  # Index of the document to show\n",
        "doc_matrix = dtm_tfidf.getrow(doc_index).toarray()\n",
        "\n",
        "# Print the words and their counts in the document\n",
        "for i, count in enumerate(doc_matrix[0]):\n",
        "    if count > 0:\n",
        "        word = index2vocabulary_item[i]\n",
        "        print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "id": "N3bwjGiaxvja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEiYoOK-sIzM"
      },
      "source": [
        "## Fit Latent Dirichlet Allocation models\n",
        "\n",
        "Finally, the LDA models are fitted. n_components is number of topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g7E6sE2sIzN"
      },
      "source": [
        "# for TF DTM\n",
        "lda_tf = LatentDirichletAllocation(n_components=10, random_state=0,verbose=1, max_iter=10)\n",
        "lda_tf.fit(dtm_tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_8bg741sIzN"
      },
      "source": [
        "## Visualizing the models with pyLDAvis\n",
        "Multidimensional scaling = Dimension reduction\n",
        "\n",
        "Can you reidentify the newsgroups? `['sci.med', 'alt.atheism', 'rec.autos', 'sci.space','rec.sport.baseball']`\n",
        "\n",
        "Hover over topics circles and terms to explore the connection between words and topics..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "lGdYc2f0sIzN"
      },
      "source": [
        "pyLDAvis.lda_model.prepare(lda_tf, dtm_tf, tf_vectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topix Modeling with TFIDF values"
      ],
      "metadata": {
        "id": "8XOv67b8GGzg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuiVrI4usIzO"
      },
      "source": [
        "# for TFIDF DTM\n",
        "lda_tfidf = LatentDirichletAllocation(n_components=10, random_state=0, verbose=1,max_iter=10)\n",
        "lda_tfidf.fit(dtm_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ysSXJxLsIzO"
      },
      "source": [
        "pyLDAvis.lda_model.prepare(lda_tfidf, dtm_tfidf, tfidf_vectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Uvl72P0asIzO"
      },
      "source": [
        "### Using different MDS functions\n",
        "\n",
        "With `sklearn` installed, other MDS functions, such as MMDS and TSNE can be used for plotting if the default PCoA is not satisfactory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le2YQ_nJsIzO"
      },
      "source": [
        "pyLDAvis.lda_model.prepare(lda_tf, dtm_tf, tf_vectorizer, mds='mmds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWF9ZPKmsIzP"
      },
      "source": [
        "pyLDAvis.lda_model.prepare(lda_tf, dtm_tf, tf_vectorizer, mds='tsne')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "05tlg25CsIzP"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}